1:"$Sreact.fragment"
2:I[7114,["874","static/chunks/874-3b2e13d78f8618dd.js","63","static/chunks/63-28726393f539b62f.js","177","static/chunks/app/layout-16f2661fbedcd9f0.js"],"Header"]
3:I[7555,[],""]
4:I[1295,[],""]
6:I[9665,[],"OutletBoundary"]
9:I[9665,[],"ViewportBoundary"]
b:I[9665,[],"MetadataBoundary"]
d:I[6614,[],""]
:HL["/_next/static/media/e4af272ccee01ff0-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/css/5542cab367cb990f.css","style"]
0:{"P":null,"b":"BcooxTDZH6TyBuPEuAUGE","p":"","c":["","posts","install-karpenter"],"i":false,"f":[[["",{"children":["posts",{"children":[["id","install-karpenter","d"],{"children":["__PAGE__",{}]}]}]},"$undefined","$undefined",true],["",["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/5542cab367cb990f.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"lang":"ko","children":["$","body",null,{"className":"__className_e8ce0c bg-white text-black dark:bg-zinc-900 dark:text-white","children":[["$","$L2",null,{}],["$","main",null,{"className":"max-w-6xl mx-auto px-4 py-8","children":["$","$L3",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":404}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],[]],"forbidden":"$undefined","unauthorized":"$undefined"}]}]]}]}]]}],{"children":["posts",["$","$1","c",{"children":[null,["$","$L3",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":[["id","install-karpenter","d"],["$","$1","c",{"children":[null,["$","$L3",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":["__PAGE__",["$","$1","c",{"children":["$L5","$undefined",null,["$","$L6",null,{"children":["$L7","$L8",null]}]]}],{},null,false]},null,false]},null,false]},null,false],["$","$1","h",{"children":[null,["$","$1","tdkLKIdIGdvsJYbx4qFEi",{"children":[["$","$L9",null,{"children":"$La"}],["$","meta",null,{"name":"next-size-adjust","content":""}]]}],["$","$Lb",null,{"children":"$Lc"}]]}],false]],"m":"$undefined","G":["$d","$undefined"],"s":false,"S":true}
e:I[6874,["874","static/chunks/874-3b2e13d78f8618dd.js","880","static/chunks/app/posts/%5Bid%5D/page-bb0e289bc5bd1f55.js"],""]
10:I[7161,["874","static/chunks/874-3b2e13d78f8618dd.js","880","static/chunks/app/posts/%5Bid%5D/page-bb0e289bc5bd1f55.js"],"default"]
f:T4f15,<h2>Prerequisite</h2>
<p>설치하기 전에 미리 설정해야하는 것들이 있다.</p>
<h3>Install helm</h3>
<p>Karpenter는 helm chart를 통해서 k8s에 설치가 가능하다. helm에 대한 내용은 나중에 포스팅해보도록 하고 간단하게 kubernetes 리소스들을 정해진 template에 맞춰서 배포할 수 있게 해주는 도구라고만 알고 넘어가자.</p>
<p>helm이 일단 먼저 필요하다. <a href="https://helm.sh/docs/intro/install/">Helm Install Docs</a></p>
<h3>AWS 리소스 생성</h3>
<p>Karpenter는 EC2 Instance를 생성해서 Node를 추가한다. AWS에 EC2를 생성할 수 있도록 AWS IAM Role을 생성해야한다.</p>
<p>또한 EC2는 VPC subnet에 Provision 되기 때문에 어떤 Subnet에 Node를 Provision할 지 Karpenter가 알아야한다.</p>
<h4>IAM Role for Karpenter Node</h4>
<pre><code class="hljs language-hcl">resource "aws_iam_role" "karpenter" {
  name               = "KarpenterNodeRole-${aws_eks_cluster.main.name}"
  assume_role_policy = data.aws_iam_policy_document.node_group_role.json
}

resource "aws_iam_role_policy_attachment" "karpenter_AmazonEKSWorkerNodePolicy" {
  role       = aws_iam_role.karpenter.name
  policy_arn = "arn:aws:iam::aws:policy/AmazonEKSWorkerNodePolicy"
}

resource "aws_iam_role_policy_attachment" "karpenter_AmazonEKS_CNI_Policy" {
  role       = aws_iam_role.karpenter.name
  policy_arn = "arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy"
}

resource "aws_iam_role_policy_attachment" "karpenter_AmazonEC2ContainerRegistryReadOnly" {
  role       = aws_iam_role.karpenter.name
  policy_arn = "arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly"
}

resource "aws_iam_role_policy_attachment" "karpenter_AmazonSSMManagedInstanceCore" {
  role       = aws_iam_role.karpenter.name
  policy_arn = "arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore"
}
</code></pre>
<h4>IAM Role for Karpenter Controller</h4>
<pre><code class="hljs language-hcl">resource "aws_iam_role" "karpenter_controller" {
  name               = "KarpenterControllerRole-${aws_eks_cluster.main.name}"
  assume_role_policy = data.aws_iam_policy_document.karpenter_controller_role.json
}

resource "aws_iam_role_policy_attachment" "karpenter_controller" {
  role       = aws_iam_role.karpenter_controller.name
  policy_arn = aws_iam_policy.karpenter_controller.arn
}

data "aws_iam_policy_document" "karpenter_controller_role" {
  version = "2012-10-17"

  statement {
    actions = ["sts:AssumeRoleWithWebIdentity"]
    effect  = "Allow"

    condition {
      test     = "StringEquals"
      variable = "${replace(aws_iam_openid_connect_provider.eks_oidc.url, "https://", "")}:sub"
      values   = ["system:serviceaccount:kube-system:karpenter"]
    }

    condition {
      test     = "StringEquals"
      variable = "${replace(aws_iam_openid_connect_provider.eks_oidc.url, "https://", "")}:aud"
      values   = ["sts.amazonaws.com"]
    }

    principals {
      identifiers = [aws_iam_openid_connect_provider.eks_oidc.arn]
      type        = "Federated"
    }
  }
}

resource "aws_iam_policy" "karpenter_controller" {
  name   = "KarpenterContollerPolicy-${aws_eks_cluster.main.name}"
  policy = data.aws_iam_policy_document.karpenter_controller_policy.json
}

data "aws_iam_policy_document" "karpenter_controller_policy" {
  statement {
    actions = [
      "ssm:GetParameter",
      "ec2:DescribeImages",
      "ec2:RunInstances",
      "ec2:DescribeSubnets",
      "ec2:DescribeSecurityGroups",
      "ec2:DescribeLaunchTemplates",
      "ec2:DescribeInstances",
      "ec2:DescribeInstanceTypes",
      "ec2:DescribeInstanceTypeOfferings",
      "ec2:DeleteLaunchTemplate",
      "ec2:CreateTags",
      "ec2:CreateLaunchTemplate",
      "ec2:CreateFleet",
      "ec2:DescribeSpotPriceHistory",
      "pricing:GetProducts"
    ]
    effect = "Allow"

    resources = ["*"]
    sid       = "Karpenter"
  }

  statement {
    actions = ["ec2:TerminateInstances"]
    effect  = "Allow"

    condition {
      test     = "StringLike"
      variable = "ec2:ResourceTag/karpenter.sh/nodepool"
      values   = ["*"]
    }

    resources = ["*"]
    sid       = "ConditionalEC2Termination"
  }

  statement {
    actions = ["iam:PassRole"]
    effect  = "Allow"

    resources = [aws_iam_role.karpenter.arn]
    sid       = "PassNodeIAMRole"
  }

  statement {
    actions = ["eks:DescribeCluster"]
    effect  = "Allow"

    resources = [aws_eks_cluster.main.arn]
    sid       = "EKSClusterEndpointLookup"
  }

  statement {
    actions = ["iam:CreateInstanceProfile"]
    effect  = "Allow"

    condition {
      test     = "StringEquals"
      variable = "aws:RequestTag/kubernetes.io/cluster/${aws_eks_cluster.main.name}"
      values   = ["owned"]
    }

    condition {
      test     = "StringEquals"
      variable = "aws:RequestTag/topology.kubernetes.io/region"
      values   = [var.region]
    }

    condition {
      test     = "StringLike"
      variable = "aws:RequestTag/karpenter.k8s.aws/ec2nodeclass"
      values   = ["*"]
    }

    resources = ["*"]
    sid       = "AllowScopedInstanceProfileCreationActions"
  }

  statement {
    actions = ["iam:TagInstanceProfile"]
    effect  = "Allow"

    condition {
      test     = "StringEquals"
      variable = "aws:ResourceTag/kubernetes.io/cluster/${aws_eks_cluster.main.name}"
      values   = ["owned"]
    }

    condition {
      test     = "StringEquals"
      variable = "aws:ResourceTag/topology.kubernetes.io/region"
      values   = [var.region]
    }

    condition {
      test     = "StringEquals"
      variable = "aws:RequestTag/kubernetes.io/cluster/${aws_eks_cluster.main.name}"
      values   = ["owned"]
    }

    condition {
      test     = "StringEquals"
      variable = "aws:RequestTag/topology.kubernetes.io/region"
      values   = [var.region]
    }

    condition {
      test     = "StringLike"
      variable = "aws:ResourceTag/karpenter.k8s.aws/ec2nodeclass"
      values   = ["*"]
    }


    condition {
      test     = "StringLike"
      variable = "aws:RequestTag/karpenter.k8s.aws/ec2nodeclass"
      values   = ["*"]
    }

    resources = ["*"]
    sid       = "AllowScopedInstanceProfileTagActions"
  }

  statement {
    actions = [
      "iam:AddRoleToInstanceProfile",
      "iam:RemoveRoleFromInstanceProfile",
      "iam:DeleteInstanceProfile"
    ]
    effect = "Allow"

    condition {
      test     = "StringEquals"
      variable = "aws:ResourceTag/kubernetes.io/cluster/${aws_eks_cluster.main.name}"
      values   = ["owned"]
    }

    condition {
      test     = "StringEquals"
      variable = "aws:ResourceTag/topology.kubernetes.io/region"
      values   = [var.region]
    }

    resources = ["*"]
    sid       = "AllowScopedInstanceProfileActions"
  }

  statement {
    actions = ["iam:GetInstanceProfile"]
    effect  = "Allow"

    resources = ["*"]
    sid       = "AllowInstanceProfileReadActions"
  }

  // for Spot instance
  statement {
    actions = [
      "sqs:ReceiveMessage",
      "sqs:GetQueueUrl",
      "sqs:DeleteMessage"
    ]
    effect = "Allow"

    resources = ["*"]
    sid       = "AllowInterruptionQueueActions"
  }
}

resource "aws_iam_service_linked_role" "spot" {
  aws_service_name = "spot.amazonaws.com"
}
</code></pre>
<h4>SQS for SPOT Instance</h4>
<p>Spot Instance를 사용하기 위해서는 SQS를 사용해야한다. Spot Instance는 on-demand Instance와 달리 언제 Interruption이 발생해서 뺏길지 모르는 Instance이다. 이런 Interruption을 Queue로 관리하기 위해 SQS를 필요로한다.</p>
<pre><code class="hljs language-hcl">resource "aws_sqs_queue" "karpenter_spot" {
  name = "Karpenter-${aws_eks_cluster.main.name}-SpotInterruptionQueue"

  message_retention_seconds = 300
  sqs_managed_sse_enabled   = true
}
</code></pre>
<h4>Set tag to Subnet &#x26; Security Group</h4>
<p>AWS에서 리소스를 관리하고 적용하는 방식을 대부분 리소스에 적힌 Tag로 관리한다.</p>
<p>Karpenter도 마찬가지다. Karpenter가 Node를 배포할 수 있는 Subnet 판단을 Subnet에 달린 tag를 보고 판단하고 Node가 사용할 Security Group도 Security Group에 달린 tag를 보고 판단한다.</p>
<p><strong>"karpenter.sh/discovery" = ${EKS_CLUSTER_NAME}</strong> 으로 Subent과 Security group에 tag를 추가해야한다.</p>
<pre><code class="hljs language-hcl">resource "aws_subnet" "private" {
  //..  중략
  tags = {
    "kubernetes.io/role/interna-elb" = 1
    "karpenter.sh/discovery"         = var.name.eks
  }
}

// EKS 생성할 때 따로 SG를 추가해주지 않았기에 Node는 EKS Cluster의 SG를 동일하게 사용한다.
// 동적으로 EKS Cluster SG에 karpenter tag를 추가하도록 한다.
resource "null_resource" "add_karpenter_tag" {
  count = length(var.vpc.subnet_ids.node)

  provisioner "local-exec" {
    command = &#x3C;&#x3C;EOT
      aws ec2 create-tags --region ${var.region} --resources ${aws_eks_cluster.main.vpc_config[0].cluster_security_group_id} --tags Key=karpenter.sh/discovery,Value=${aws_eks_cluster.main.name}
    EOT
  }
}

</code></pre>
<h3>Install Karpenter in EKS</h3>
<p>필요한 AWS 리소스는 모두 생성했다. 이제 EKS에 Karpenter를 설치해보자.</p>
<h4>Update aws-auth ConfigMap</h4>
<p>먼저 aws-auth ConfigMap을 변경해줘야한다.</p>
<p>kubectl 명령으로 ConfigMap 수정을 진행한다. ${}로 표시한 값들은 각자 AWS 계정에 맞는 값을 입력해주면 된다.</p>
<pre><code class="hljs language-bash">kubectl edit configmap aws-auth -n kube-system
</code></pre>
<pre><code class="hljs language-yaml"><span class="hljs-comment"># Add section in aws-auth configmap</span>
<span class="hljs-bullet">-</span> <span class="hljs-attr">groups:</span>
    <span class="hljs-bullet">-</span> <span class="hljs-string">system:bootstrappers</span>
    <span class="hljs-bullet">-</span> <span class="hljs-string">system:nodes</span>
  <span class="hljs-attr">rolearn:</span> <span class="hljs-string">arn:${AWS_PARTITION}:iam::${AWS_ACCOUNT_ID}:role/KarpenterNodeRole-${CLUSTER_NAME}</span>
  <span class="hljs-attr">username:</span> <span class="hljs-string">system:node:{{EC2PrivateDNSName}}</span>
</code></pre>
<h4>Install using helm</h4>
<p>Helm chart를 이용해서 Karpenter를 설치한다.</p>
<p><strong>values.yaml</strong></p>
<p>${}로 표시된 values는 각자가 설정한 AWS 리소스를 명시하면 된다.</p>
<pre><code class="hljs language-yaml"><span class="hljs-comment"># Service Account에서 사용할 IAM Role ARN 정의</span>
<span class="hljs-attr">serviceAccount:</span>
  <span class="hljs-attr">annotations:</span>
    <span class="hljs-attr">eks.amazonaws.com/role-arn:</span> <span class="hljs-string">${KarpenterControllerRole}</span>

<span class="hljs-comment"># Replica count</span>
<span class="hljs-attr">replicas:</span> <span class="hljs-number">1</span>

<span class="hljs-comment"># Karpenter Controller가 Karpenter가 생성한 Node 위에서 실행되지 않도록</span>
<span class="hljs-comment"># 기본 설정한 default node group 위에서만 실행되도록 affinity를 설정해준다.</span>
<span class="hljs-attr">affinity:</span>
  <span class="hljs-attr">nodeAffinity:</span>
    <span class="hljs-attr">requiredDuringSchedulingIgnoredDuringExecution:</span>
      <span class="hljs-attr">nodeSelectorTerms:</span>
        <span class="hljs-bullet">-</span> <span class="hljs-attr">matchExpressions:</span>
            <span class="hljs-bullet">-</span> <span class="hljs-attr">key:</span> <span class="hljs-string">karpenter.sh/nodepool</span>
              <span class="hljs-attr">operator:</span> <span class="hljs-string">DoesNotExist</span>
            <span class="hljs-bullet">-</span> <span class="hljs-attr">key:</span> <span class="hljs-string">eks.amazonaws.com/nodegroup</span>
              <span class="hljs-attr">operator:</span> <span class="hljs-string">In</span>
              <span class="hljs-attr">values:</span> [<span class="hljs-string">"default_node_group"</span>]

<span class="hljs-comment"># Controller의 리소스를 명시한다</span>
<span class="hljs-attr">controller:</span>
  <span class="hljs-attr">resources:</span>
    <span class="hljs-attr">requests:</span>
      <span class="hljs-attr">cpu:</span> <span class="hljs-string">50m</span>
      <span class="hljs-attr">memory:</span> <span class="hljs-string">512Mi</span>
    <span class="hljs-attr">limits:</span>
      <span class="hljs-attr">memory:</span> <span class="hljs-string">512Mi</span>

<span class="hljs-comment"># EKS cluster 이름과 위에서 생성한 SQS queue 이름을 입력한다.</span>
<span class="hljs-attr">settings:</span>
  <span class="hljs-attr">clusterName:</span> <span class="hljs-string">${EKS_CLUSTER_NAME}</span>
  <span class="hljs-attr">interruptionQueue:</span> <span class="hljs-string">Karpenter-${EKS_CLUSTER_NAME}-SpotInterruptionQueue</span>
</code></pre>
<p><strong>Helm install</strong></p>
<p>자신의 k8s 버전에 맞는 KARPENTER_VERSION을 사용하자. <a href="https://karpenter.sh/docs/upgrading/compatibility/">Compatibility</a> 페이지에서 호환되는 버전을 확인하면 된다.</p>
<pre><code class="hljs language-bash">helm upgrade --install karpenter oci://public.ecr.aws/karpenter/karpenter --version <span class="hljs-variable">${KARPENTER_VERSION}</span> -n kube-system -f values.yaml
</code></pre>
<h4>Result</h4>
<p>정상적으로 설치가 끝나면 이렇게 Karpenter pod를 확인할 수 있다.</p>
<p><img src="/images/posts/contents/install-karpenter/karpenter-controller-pod.png" alt="karpenter-controller-pod"></p>
<h3>Set Node</h3>
<p>Karpenter Controller 설치가 끝났으면 이제 Karpenter가 관리할 Node의 정의를 해줘서 EC2 Instance를 자동으로 Provision하여 Node를 추가하도록 해보자.</p>
<h4>Node Class</h4>
<pre><code class="hljs language-yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">karpenter.k8s.aws/v1</span>
<span class="hljs-attr">kind:</span> <span class="hljs-string">EC2NodeClass</span>
<span class="hljs-attr">metadata:</span>
  <span class="hljs-attr">name:</span> <span class="hljs-string">default</span>
<span class="hljs-attr">spec:</span>
  <span class="hljs-attr">amiFamily:</span> <span class="hljs-string">AL2023</span>
  <span class="hljs-attr">amiSelectorTerms:</span>
    <span class="hljs-bullet">-</span> <span class="hljs-attr">alias:</span> <span class="hljs-string">al2023@latest</span>
  <span class="hljs-attr">subnetSelectorTerms:</span>
    <span class="hljs-bullet">-</span> <span class="hljs-attr">tags:</span>
        <span class="hljs-attr">karpenter.sh/discovery:</span> <span class="hljs-string">${EKS_CLUSTER_NAME}</span>
  <span class="hljs-attr">securityGroupSelectorTerms:</span>
    <span class="hljs-bullet">-</span> <span class="hljs-attr">tags:</span>
        <span class="hljs-attr">karpenter.sh/discovery:</span> <span class="hljs-string">${EKS_CLUSTER_NAME}</span>
  <span class="hljs-attr">role:</span> <span class="hljs-string">"${KARPENTER_NODE_ROLE}"</span>
</code></pre>
<h4>Node pool</h4>
<pre><code class="hljs language-yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">karpenter.sh/v1</span>
<span class="hljs-attr">kind:</span> <span class="hljs-string">NodePool</span>
<span class="hljs-attr">metadata:</span>
  <span class="hljs-attr">name:</span> <span class="hljs-string">default</span>
<span class="hljs-attr">spec:</span>
  <span class="hljs-attr">template:</span>
    <span class="hljs-attr">metadata:</span>
    <span class="hljs-attr">spec:</span>
      <span class="hljs-attr">nodeClassRef:</span>
        <span class="hljs-attr">group:</span> <span class="hljs-string">karpenter.k8s.aws</span>
        <span class="hljs-attr">kind:</span> <span class="hljs-string">EC2NodeClass</span>
        <span class="hljs-attr">name:</span> <span class="hljs-string">default</span>
      <span class="hljs-attr">expireAfter:</span> <span class="hljs-string">720h</span>
      <span class="hljs-attr">terminationGracePeriod:</span> <span class="hljs-string">10m</span>
      <span class="hljs-attr">requirements:</span>
        <span class="hljs-bullet">-</span> <span class="hljs-attr">key:</span> <span class="hljs-string">karpenter.k8s.aws/instance-family</span>
          <span class="hljs-attr">operator:</span> <span class="hljs-string">In</span>
          <span class="hljs-attr">values:</span>
            <span class="hljs-bullet">-</span> <span class="hljs-string">t4g</span>
        <span class="hljs-bullet">-</span> <span class="hljs-attr">key:</span> <span class="hljs-string">karpenter.k8s.aws/instance-cpu</span>
          <span class="hljs-attr">operator:</span> <span class="hljs-string">In</span>
          <span class="hljs-attr">values:</span>
            <span class="hljs-bullet">-</span> <span class="hljs-string">"2"</span>
            <span class="hljs-bullet">-</span> <span class="hljs-string">"4"</span>
        <span class="hljs-bullet">-</span> <span class="hljs-attr">key:</span> <span class="hljs-string">karpenter.k8s.aws/instance-memory</span>
          <span class="hljs-attr">operator:</span> <span class="hljs-string">In</span>
          <span class="hljs-attr">values:</span>
            <span class="hljs-bullet">-</span> <span class="hljs-string">"4096"</span>
            <span class="hljs-bullet">-</span> <span class="hljs-string">"8192"</span>
            <span class="hljs-bullet">-</span> <span class="hljs-string">"16384"</span>
        <span class="hljs-bullet">-</span> <span class="hljs-attr">key:</span> <span class="hljs-string">karpenter.sh/capacity-type</span>
          <span class="hljs-attr">operator:</span> <span class="hljs-string">In</span>
          <span class="hljs-attr">values:</span>
            <span class="hljs-bullet">-</span> <span class="hljs-string">spot</span>
            <span class="hljs-bullet">-</span> <span class="hljs-string">on-demand</span>
        <span class="hljs-bullet">-</span> <span class="hljs-attr">key:</span> <span class="hljs-string">topology.kubernetes.io/zone</span>
          <span class="hljs-attr">operator:</span> <span class="hljs-string">In</span>
          <span class="hljs-attr">values:</span>
            <span class="hljs-bullet">-</span> <span class="hljs-string">ap-northeast-2a</span>
        <span class="hljs-bullet">-</span> <span class="hljs-attr">key:</span> <span class="hljs-string">kubernetes.io/arch</span>
          <span class="hljs-attr">operator:</span> <span class="hljs-string">In</span>
          <span class="hljs-attr">values:</span>
            <span class="hljs-bullet">-</span> <span class="hljs-string">arm64</span>
  <span class="hljs-attr">disruption:</span>
    <span class="hljs-attr">consolidationPolicy:</span> <span class="hljs-string">WhenEmptyOrUnderutilized</span>
    <span class="hljs-attr">consolidateAfter:</span> <span class="hljs-string">10m</span>
  <span class="hljs-attr">limit:</span>
    <span class="hljs-attr">cpu:</span> <span class="hljs-number">20</span>
    <span class="hljs-attr">memory:</span> <span class="hljs-string">80Gi</span>
  <span class="hljs-attr">weight:</span>
</code></pre>
<h2>Result</h2>
<p>Node Class와 Node Pool 설정까지 끝나면 Node에 컴퓨팅 자원이 부족할 때 Karpenter가 Node를 새로 추가한다.</p>
<p>Karpenter가 새로 추가한 Node에는 아래처럼 <strong>karpenter.k8s.aws/</strong> 로 시작하는 label 들이 붙어있다.</p>
<p><img src="/images/posts/contents/install-karpenter/karpenter-node.png" alt="karpenter-node"></p>
<h2>Finished</h2>
<p>Karpenter로 Node를 유연하게 Provisioning 되는 것까지 완료했다.</p>
<p>Side Project이다 보니 당연하게 비용을 최저로 나가게 하고 싶은 맘이 컸다. 그래서 node pool은 최대한 spot이 뜨게 하려고 node pool에 추가했고 t class로 node를 띄웠다.</p>
<p>Side Project에서 캐시카우가 점점 늘어나게 되면 고민을 해보겠지만 지금 당장 트래픽이 엄청 많은 것도 아니고 t class로도 문제없이 돌릴 수 있는 상황이기 때문에 최대함 비용이 안나가는 걸 최우선으로 했다.</p>5:["$","div",null,{"className":"max-w-4xl mx-auto p-4 sm:p-8","children":[["$","div",null,{"className":"mb-8","children":["$","$Le",null,{"href":"/","className":"text-accent hover:underline flex items-center","children":[["$","svg",null,{"className":"w-4 h-4 mr-1","fill":"none","stroke":"currentColor","viewBox":"0 0 24 24","xmlns":"http://www.w3.org/2000/svg","children":["$","path",null,{"strokeLinecap":"round","strokeLinejoin":"round","strokeWidth":"2","d":"M10 19l-7-7m0 0l7-7m-7 7h18"}]}],"Back to home"]}]}],["$","h1",null,{"className":"text-4xl font-extrabold text-foreground mb-4 leading-tight","children":"EKS에 Karpenter 설치"}],["$","p",null,{"className":"text-lg text-muted-foreground mb-6","children":"2025-07-07"}],["$","div",null,{"className":"mb-6 flex flex-wrap gap-2","children":[["$","span","infra",{"className":"bg-blue-600/10 text-blue-400 px-2 py-0.5 rounded text-xs font-medium border border-blue-600/20","children":"infra"}]]}],["$","article",null,{"className":"prose lg:prose-xl prose-lg dark:prose-invert max-w-none","children":["$","div",null,{"dangerouslySetInnerHTML":{"__html":"$f"}}]}],["$","div",null,{"className":"mt-16 pt-8 border-t border-card","children":[["$","h2",null,{"className":"text-2xl font-bold text-foreground mb-6","children":"Comments"}],["$","$L10",null,{"repo":"comstering/comstering.github.io","repoId":"MDEwOlJlcG9zaXRvcnkzNjI0MjQ3NDk=","category":"Announcements","categoryId":"MDE4OkRpc2N1c3Npb25DYXRlZ29yeTMyOTQ4OTYw","mapping":"pathname","strict":"0","reactionsEnabled":"1","emitMetadata":"0","inputPosition":"top","theme":"dark_high_contrast","lang":"ko","loading":"lazy"}]]}]]}]
a:[["$","meta","0",{"charSet":"utf-8"}],["$","meta","1",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
7:null
8:null
c:[["$","title","0",{"children":"EKS에 Karpenter 설치"}],["$","meta","1",{"name":"description","content":"EKS에 Karpenter 설치해서 유연한 Node Autoscaling 적용하기"}],["$","meta","2",{"name":"keywords","content":"infra, aws, eks, karpenter, kubernetes, k8s"}],["$","meta","3",{"property":"og:title","content":"EKS에 Karpenter 설치"}],["$","meta","4",{"property":"og:description","content":"EKS에 Karpenter 설치해서 유연한 Node Autoscaling 적용하기"}],["$","meta","5",{"property":"og:url","content":"https://comstering.github.io/posts/install-karpenter"}],["$","meta","6",{"property":"og:image","content":"https://comstering.github.io/karpenter.png"}],["$","meta","7",{"property":"og:type","content":"article"}],["$","meta","8",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","9",{"name":"twitter:title","content":"EKS에 Karpenter 설치"}],["$","meta","10",{"name":"twitter:description","content":"EKS에 Karpenter 설치해서 유연한 Node Autoscaling 적용하기"}],["$","meta","11",{"name":"twitter:image","content":"https://comstering.github.io/karpenter.png"}],["$","link","12",{"rel":"icon","href":"/favicon.ico","type":"image/x-icon","sizes":"1024x1024"}]]
